{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"10_overview/","title":"Overview","text":"<p>libspot is a <code>C</code> library to flag outliers in high-throughput streaming data.</p>"},{"location":"10_overview/#goal","title":"Goal","text":"<p>libspot implements the SPOT algorithm. The latter is the result of research work that aims to detect outliers (extreme events) in streams without distribution assumption. Briefly, it is the poor man's anomaly detector.</p> <p>It should be used when we have either no information (and no strong assumption) about the data you want to monitor (a kind of blind monitoring).</p>"},{"location":"10_overview/#whats-new","title":"What's new?","text":"<p>While the first implementation of libspot was in <code>C++</code>, this new version has been entirely re-implemented in <code>C</code>. Actually OOP is a bit overkill for this task and using <code>C</code> may ease integrations (target systems and language interoperability). In addition, some boilerplate code has been removed to keep only the core algorithm. Here are the project specs:</p> <ul> <li><code>c99</code> standard: modern <code>C</code> but not too much</li> <li>clean API: few meaningful functions to run the algorithm</li> <li><code>-nostdlib</code>: libspot does not depend on the standard library</li> <li>decent testing: remember that there is statistics behind </li> </ul> <p>The development of libspot tries to follow some principles:</p> <ul> <li> UNIX philosophy: do one thing and do it well. It implies that the library should not embed code that provides too specific features, extra utilities or additional abstraction layers. In return, the project must also meet high quality: code, API, documentation and testing are the main undertakings.</li> <li> Lightness: the library should have a low footprint. Actually the SPOT algorithm is against the flow: far from all the deep models that more and more overwhelm our daily life. Obviously it is also far less powerful  but its use-cases are definitely different. In a word, SPOT is a cheap algorithm that must be able to run on cheap systems.</li> <li> Portability/Extensibility: in relation with the lightness goal, the library should be easily integrable to any ecosystem. This is why libspot is developed in <code>C99</code> without depending on the standard library. In addition, I would like to provide some bindings that will help developers using the algorithm.</li> </ul>"},{"location":"15_install/","title":"Install","text":"<p>If you are only interested in the python interface the [dynamic] library is packaged with the python wheel.</p> <p>The classical way is to build from sources.</p> <pre><code>git clone github.com/asiffer/libspot\ncd libspot\nmake\n</code></pre> <p>The <code>make</code> command builds both the static and the dynamic libraries. Then to install libs and headers:</p> <pre><code>sudo make install\n</code></pre> <p>Info</p> <p>By default it install the libraries to <code>/usr/lib</code> and headers to <code>/usr/include/spot</code>. You can change it through <code>INSTALL_HEAD_DIR</code> and <code>INSTALL_LIB_DIR</code> variables: <pre><code>sudo make install INSTALL_HEAD_DIR=/tmp/spot INSTALL_LIB_DIR=/tmp\n</code></pre> Or you can use the <code>DESTDIR</code> (unset) or <code>PREFIX</code> variables (set to <code>/usr</code>). Here is the extract of the Makefile: <pre><code>DESTDIR =\nPREFIX = /usr\nINSTALL_HEAD_DIR = $(DESTDIR)$(PREFIX)/include/spot\nINSTALL_LIB_DIR = $(DESTDIR)$(PREFIX)/lib\n</code></pre></p> <p>You can remove the library with the <code>uninstall</code> command. <pre><code>sudo make uninstall\n</code></pre></p>"},{"location":"20_get_started/","title":"Get started","text":"<p>Inside your code, you just have to add the <code>spot.h</code> header file.</p> <pre><code>#include \"spot.h\"\n</code></pre> <p>One paramount point is that <code>libspot</code> does not know how to allocate/free memory (it does not know <code>libc</code> by design). So you have to provide these functions. By default you can pass the common <code>malloc</code> and <code>free</code> functions from <code>stdlib.h</code>.</p> <pre><code>#include \"spot.h\"\n#include &lt;stdlib.h&gt;\n\nset_allocators(malloc, free);\n</code></pre> <p>Ok, now you want to use the SPOT algorithm. You can allocate a <code>Spot</code> object either on stack or on heap.</p> <pre><code>// stack allocation\nstruct Spot spot;\n// or heap allocation\nstruct Spot* spot_ptr = (struct Spot*)malloc(sizeof(struct Spot));\n</code></pre> <p>Then you must init that structure with the <code>spot_init</code> function.</p> <pre><code>// here we assume stack allocation\nstruct Spot spot;\n// init with SPOT parameters\nint status = spot_init(\n        &amp;spot, // pointer to the allocated structure\n        1e-4,  // q: anomaly probability\n        0,     // low: observe upper tail\n        1,     // discard_anomalies: flag anomalies\n        0.998, // level: tail quantile (the 0.2% higher values shapes the tail)\n        200    // max_excess: number of data to keep to summarize the tail\n    );\n// you can check the initialization\nif (status &lt; 0) {\n    // print error\n    char buffer[100];\n    error_msg(-status, buffer, 100);\n    printf(\"ERROR %d: %s\\n\", -status, buffer);\n}\n</code></pre> <p>Basically <code>q</code> is the anomaly probability. The algorithm will flag events that have a lower probability than <code>q</code>. In practice, it must be very low (like <code>1e-3</code> or less).</p> <p>The <code>low</code> parameter just defines whether we flag high (<code>low = 0</code>) of low (<code>low = 1</code>) values while <code>discard_anomalies</code> says that we want to reject anomalies.</p> <p>The <code>level</code> should be a high quantile (a value close to <code>1</code>). It is useful to delimitate the tail of the distribution. One may use values like <code>0.98</code>, <code>0.99</code> or <code>0.995</code>.</p> <p>Finally <code>max_excess</code> is the number of data that will be kept to model the tail of the distribution.</p> <p>You can read more about the parameters in the dedicated section.</p> <p>Before prediction, we commonly need to fit the algorithm with first data. In practice you must provide a buffer of <code>double</code> (pointer + size of the buffer). How many records are needed? Briefly, few thousands (like 2000) but it depends on the parameters passed to SPOT (and also whether you have enough data).</p> <pre><code>// double* initial_data = ...\n// unsigned long size = ...\nstatus = spot_fit(&amp;spot, initial_data, size);\nif (status &lt; 0) {\n    // print error\n    char buffer[100];\n    error_msg(-status, buffer, 100);\n    printf(\"ERROR %d: %s\\n\", -status, buffer);\n}\n</code></pre>"},{"location":"20_get_started/#full-example","title":"Full example","text":"<p>Here we present a basic example where the SPOT algorithm is run on an exponential stream.</p> <pre><code>// basic.c\n// BUILD:\n// $ make\n// $ cc -o /tmp/basic examples/basic.c -Idist/ -Ldist/ -l:libspot.so.2.0b0 -lm\n// RUN:\n// $ LD_LIBRARY_PATH=dist /tmp/basic\n\n#include \"spot.h\"\n#include &lt;math.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;time.h&gt;\n\n// U(0, 1)\ndouble runif() { return (double)rand() / (double)RAND_MAX; }\n\n// Exp(1)\ndouble rexp() { return -log(runif()); }\n\nint main() {\n    // set random seed\n    srand(1);\n    // provide allocators to libspot\n    set_allocators(malloc, free);\n    // stack allocation\n    struct Spot spot;\n    int status = 0;\n    // init the structure with some parameters\n    status = spot_init(\n        &amp;spot,\n        1e-4,  // q: anomaly probability\n        0,     // low: observe upper tail\n        1,     // discard_anomalies: flag anomalies\n        0.998, // level: tail quantile (the 1% higher values shapes the tail)\n        200    // max_excess: number of data to keep to summarize the tail\n    );\n\n    if (status &lt; 0) {\n        return -status;\n    }\n\n    // initial data (for the fit)\n    unsigned long const N = 20000;\n    double initial_data[N];\n    for (unsigned long i = 0; i &lt; N; i++) {\n        initial_data[i] = rexp();\n    }\n\n    // fit\n    status = spot_fit(&amp;spot, initial_data, N);\n    if (status &lt; 0) {\n        return -status;\n    }\n\n    // now we can run the algorithm\n    int K = 50000000;\n    int normal = 0;\n    int excess = 0;\n    int anomaly = 0;\n\n    clock_t start = clock();\n    for (int k = 0; k &lt; K; k++) {\n        // rexp();\n        switch (spot_step(&amp;spot, rexp())) {\n        case ANOMALY:\n            anomaly++;\n            break;\n        case EXCESS:\n            excess++;\n            break;\n        case NORMAL:\n            normal++;\n            break;\n        }\n    }\n    clock_t end = clock();\n\n    printf(\"%lf\\n\", (double)(end - start) / (double)(CLOCKS_PER_SEC));\n    printf(\"ANOMALY=%d EXCESS=%d NORMAL=%d\\n\", anomaly, excess, normal);\n    printf(\"Z=%.6f T=%.6f\\n\", spot.anomaly_threshold, spot.excess_threshold);\n    return 0;\n}\n</code></pre>"},{"location":"30_parameters/","title":"Parameters","text":"<p>SPOT can be very powerful, once the parameters are coherent. This is not about precision mechanics but there is rule of thumbs you can follow.</p>"},{"location":"30_parameters/#detection","title":"Detection","text":"<p>The main parameter is <code>q</code>. It defines the probability of an abnormal event. For example, if <code>q = 0.001</code>, it means that the algorithm will consider events with a probability lower than <code>0.1%</code> as anomalies.</p> <p>The impact of <code>q</code> defines the trade-off between the detection rate and the false positive rate. When <code>q</code> is low (e.g. <code>1e-8</code>), SPOT will flag only very extreme events so the false positive rate will be low (very extreme events are likely to be true anomalies) and so the detection rate (there will be more unflagged anomalies). The revert phenomenon occurs when <code>q</code> is \"high\".</p> <code>q</code> Example Detection rate False positive rate low <code>1e-8</code> low low high <code>1e-3</code> high high"},{"location":"30_parameters/#biasvariance-tradeoff","title":"Bias/variance tradeoff","text":"<p>The parameters <code>level</code> and <code>size</code> (from the <code>spot_fit</code> function) are involved in the fit step of the algorithm.</p> <p>The <code>size</code> is the number of data used for calibration while <code>1-level</code> represents the proportion of these initial data that belong to the tail of the distribution (<code>level</code> is then a high quantile in practice). For example, let us use <code>size = 1000</code> and <code>level = 0.99</code>. The algorithm will drop the 990 lowest data and will keep the 10 highest to make a first tail fit.</p> <p>Warning</p> <p>In practice, the user must ensure that <code>n_init * (1 - level)</code> is high enough to perform the fit (at least few dozens of data). See the paragraph below.</p> <p>When <code>size</code> is fixed, the parameter <code>level</code> tunes the bias/variance tradeoff. We have explained that the number of data to perform the fit is <code>(1-level)*size</code>. If <code>level</code> is high (close to 1), we are more likely to shape the right tail (low bias) but as the number of fitting data is low, the latter will be more variable (high variance). Conversely if <code>level</code> is not too close to 1, we will have more data to fit the tail (low variance) but maybe our fit will involve data that do not belong to the tail (high bias).</p> <code>level</code> Example Bias Variance low <code>0.95</code> high low high <code>0.999</code> low high <p>Ideally, if you have plenty of records, you can take a very high <code>level</code> without worrying about the variance.</p> <p>Warning</p> <p>Remember also that <code>1-level</code> cannot be lower that <code>q</code> otherwise it leads to a contradiction between what should be flagged and what should be in the tail.</p>"},{"location":"30_parameters/#bounded-memory","title":"Bounded memory","text":"<p>In theory, the number of data in the tail can grow indifinetely while monitoring an infinite stream. Everyone knows that memory resources are limited so we cannot store all of the data to update the tail. Here comes the <code>max_excess</code> parameters: it defines the number of tail data we will keep.</p> <p>Moreover, it creates a memory vanishing effect since the model will keep only the last <code>max_excess</code> tail data to perform the fit. Thus, it must be high enough to perform a good fit in terms of bias and variance (see the paragraph above) but beware of the tail dynamics: if you need to quickly adapt to the \"new\" shape of the tail, <code>max_excess</code> should not be too high (one may advice few hundreds but it could be more if the monitored stream is stable).</p>"},{"location":"50_python/","title":"Python","text":""},{"location":"50_python/#install","title":"Install","text":"<p>You can install the python bindings through <code>pip</code>. It ships the whole library (so you don't have to install it beforehand).</p> <pre><code>pip install libspot\n</code></pre> <p>The bindings are implemented as a CPython <code>C</code> extension (i.e. directly using the CPython API). So the overhead is low (but it deserves to be evaluated).</p> <p>Info</p> <p>This <code>C</code> extension uses the CPython Limited API. It makes the built wheels compatible with multiple versions of Python. So in practice, a single wheel is built for each OS et can be installed along with any <code>CPython&gt;=3.6</code>.</p>"},{"location":"50_python/#get-started","title":"Get started","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom libspot import ANOMALY, Spot\n\n# Fancyness ---------------------------------------------------------------- #\ncolors = {\n    \"bg\": \"#242933\",\n    \"stream\": \"#88c0d0\",\n    \"threshold\": \"#ebcb8b\",\n    \"anomaly\": \"#bf616a\",\n    \"axes\": \"#eceff4\",\n}\nstyle = {\n    \"figure.facecolor\": colors[\"bg\"],\n    \"axes.facecolor\": colors[\"bg\"],\n    \"axes.edgecolor\": colors[\"axes\"],\n    \"xtick.color\": colors[\"axes\"],\n    \"ytick.color\": colors[\"axes\"],\n    \"font.family\": \"monospace\",\n    \"font.monospace\": \"IBM Plex Mono\",\n    \"font.size\": 20,\n    \"svg.fonttype\": \"none\",\n    \"lines.markersize\": 10.0,\n}\n# -------------------------------------------------------------------------- #\n\n\nTRAIN = np.random.standard_normal(size=10_000)\nSTREAM = np.random.standard_normal(size=100_000)\nTHRESHOLD = np.zeros(STREAM.size)\n\nspot = Spot(q=5e-6, max_excess=2000, level=0.99)\nspot.fit(TRAIN)\n\nAx = []\nAy = []\nfor i, x in enumerate(STREAM):\n    r = spot.step(x)\n    if r == ANOMALY:\n        Ax.append(i)\n        Ay.append(x)\n    THRESHOLD[i] = spot.anomaly_threshold\n\n\nwith plt.rc_context(style):\n    fig, ax = plt.subplots(figsize=(14, 6))\n    ax.plot(STREAM, color=colors[\"stream\"])\n    ax.plot(THRESHOLD, ls=\"--\", lw=2, color=colors[\"threshold\"])\n    ax.scatter(Ax, Ay, color=colors[\"anomaly\"])\n    fig.tight_layout()\n    fig.savefig(\"../docs/img/basic.svg\")\n</code></pre>"},{"location":"51_javascript/","title":"Javascript","text":"<p>libspot has also been ported to the browser (and more generally to the <code>js</code> ecosystem) through webassembly  thanks to emscripten.</p>"},{"location":"51_javascript/#install","title":"Install","text":"<p>You can get the library through <code>npm</code> (or other package manager).</p> npmyarn <pre><code>npm install libspot\n</code></pre> <pre><code>yarn add libspot\n</code></pre> <p>You then get a typescript library that wraps the webassembly code.</p>"},{"location":"51_javascript/#get-started","title":"Get started","text":"<pre><code>import { Spot, ANOMALY } from \"libspot\";\nimport Plotly from \"plotly.js-dist-min\";\n\n// Fancyness -----------------------------------------------------------------\nconst colors = {\n  bg: \"#242933\",\n  stream: \"#88c0d0\",\n  threshold: \"#ebcb8b\",\n  anomaly: \"#bf616a\",\n  axes: \"#eceff4\",\n};\n\n// Plotly structures ---------------------------------------------------------\nconst layout = {\n  plot_bgcolor: colors.bg,\n  paper_bgcolor: colors.bg,\n  xaxis: {\n    linecolor: colors.axes,\n    tickfont: {\n      color: colors.axes,\n      showgrid: false,\n    },\n  },\n  yaxis: {\n    linecolor: colors.axes,\n    tickfont: {\n      color: colors.axes,\n      showgrid: false,\n    },\n  },\n};\n\nlet stream = {\n  x: [],\n  y: [],\n  mode: \"lines\",\n  name: \"Data\",\n  line: {\n    color: colors.stream,\n  },\n};\n\nlet anomalies = {\n  x: [],\n  y: [],\n  mode: \"markers\",\n  name: \"Anomalies\",\n  marker: {\n    color: colors.anomaly,\n  },\n};\n\nconst gaussianRandom = () =&gt; {\n  // N(0, 1)\n  const u = 1 - Math.random(); // Converting [0,1) to (0,1]\n  const v = Math.random();\n  return Math.sqrt(-2.0 * Math.log(u)) * Math.cos(2.0 * Math.PI * v);\n};\n\n// Spot job ------------------------------------------------------------------\nconst s = new Spot({ q: 1e-6, level: level, maxExcess: 1000 });\n\n// fit to input data\nconst train = Float64Array.from({ length: 20000 }, () =&gt; gaussianRandom());\ns.fit(train);\n\n// run\nfor (let i = 0; i &lt; 1000; i++) {\n  const x = gaussianRandom();\n\n  stream.x.push(i);\n  stream.y.push(x);\n\n  let r = s.step(x);\n  if (r === ANOMALY) {\n    anomalies.x.push(i);\n    anomalies.y.push(x);\n  }\n}\n\n// plot\nPlotly.newPlot(\"myDiv\", [stream, anomalies], layout);\n</code></pre>"},{"location":"60_about/","title":"About","text":"<p>This library is an extension of research work previously published at KDD'17 conference. If libspot contributes to a project that leads to a scientific publication, please acknowledge this fact by citing the publication:</p> <p>Cite</p> <p>Siffer, A. , Fouque, P. A., Termier, A., &amp; Largouet, C. (2017, August). Anomaly Detection in Streams with Extreme Value Theory. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 1067-1075). ACM.</p> <p>Here is the BibTeX record:</p> <pre><code>@inproceedings{siffer2017anomaly,\n  title={Anomaly detection in streams with extreme value theory},\n  author={Siffer, Alban and Fouque, Pierre-Alain and Termier, Alexandre and Largouet, Christine},\n  booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},\n  pages={1067--1075},\n  year={2017}\n}\n</code></pre>"},{"location":"70_API/","title":"API","text":""},{"location":"70_API/#typedefs","title":"Typedefs","text":"malloc_fn <pre><code>typedef void *(* malloc_fn) (__SIZE_TYPE__)\n</code></pre> <p><code>malloc_fn</code> is a pointer to a malloc-type function i.e. with prototype: <code>void * malloc(size_t)</code></p> free_fn <pre><code>typedef void(* free_fn) (void *)\n</code></pre> <p><code>free_fn</code> is a pointer to a free-type function i.e. with prototype: <code>void free(void*)</code></p> frexp_fn <pre><code>typedef double(* frexp_fn) (double, int *)\n</code></pre> <p><code>frexp_fn</code> is a pointer to a frexp-type function i.e. with prototype: <code>double frexp_fn(double, int*)</code></p> ldexp_fn <pre><code>typedef double(* ldexp_fn) (double, int)\n</code></pre> <p><code>ldexp_fn</code> is a pointer to a ldexp-type function i.e. with prototype: <code>double ldexp_fn(double, int*)</code></p> real_function <pre><code>typedef double(* real_function) (double, void *)\n</code></pre> <p><code>real_function</code> defines a pointer to a univariate function that can require extra paramaters (second argument)</p>"},{"location":"70_API/#enum","title":"Enum","text":"LibspotError <pre><code>enum LibspotError {\n    ERR_MEMORY_ALLOCATION_FAILED = 1000,\n    ERR_LEVEL_OUT_OF_BOUNDS,\n    ERR_Q_OUT_OF_BOUNDS,\n    ERR_EXCESS_THRESHOLD_IS_NAN,\n    ERR_ANOMALY_THRESHOLD_IS_NAN,\n    ERR_DATA_IS_NAN,\n};\n</code></pre> <p>Constants to store libspot errors.</p> Name Description <code>ERR_MEMORY_ALLOCATION_FAILED</code> Allocation of the backing array failed. <code>ERR_LEVEL_OUT_OF_BOUNDS</code> The level parameter must between 0 and 1. <code>ERR_Q_OUT_OF_BOUNDS</code> The q parameter must be between 0 and 1-level. <code>ERR_EXCESS_THRESHOLD_IS_NAN</code> The excess threshold has not been initialized. <code>ERR_ANOMALY_THRESHOLD_IS_NAN</code> The anomaly threshold has not been initialized. <code>ERR_DATA_IS_NAN</code> The input data is NaN. SpotResult <pre><code>enum SpotResult {\n    NORMAL = 0,\n    EXCESS = 1,\n    ANOMALY = 2,\n};\n</code></pre> <p>Possible outputs of a Spot step.</p> Name Description <code>NORMAL</code> Data is normal. <code>EXCESS</code> Data is in the tail (so the model has been updated) <code>ANOMALY</code> Data is beyond the anomaly threshold."},{"location":"70_API/#structures","title":"Structures","text":"Ubend <pre><code>struct Ubend {\n    unsigned long cursor;\n    unsigned long capacity;\n    double last_erased_data;\n    int filled;\n    double * data;\n};\n</code></pre> <p>This container is a kind of circular vector.</p> <p>First it is empty. Then we feed it with data until its max capacity is reached (transitory state). When it is full, the earlier data erase the older one (cruise state). </p> Member Description <code>cursor</code> Current position inside the container. <code>capacity</code> Max storage. <code>last_erased_data</code> Last erased value (i.e. replaced by a new one) <code>filled</code> Container fill status (1 = filled, 0 = not filled) <code>data</code> Data container. Peaks <pre><code>struct Peaks {\n    double e;\n    double e2;\n    double min;\n    double max;\n    struct Ubend container;\n};\n</code></pre> <p>Stucture that computes stats about the peaks.</p> Member Description <code>e</code> Sum of the elements. <code>e2</code> Sum of the square of the elements. <code>min</code> Minimum of the elements. <code>max</code> Maximum of the elements. <code>container</code> Underlying data container. Tail <pre><code>struct Tail {\n    double gamma;\n    double sigma;\n    struct Peaks peaks;\n};\n</code></pre> <p>Stucture that embeds GPD parameter (GPD tail actually)</p> Member Description <code>gamma</code> GPD gamma parameter. <code>sigma</code> GPD sigma parameter. <code>peaks</code> Underlyning Peaks structure. Spot <pre><code>struct Spot {\n    double q;\n    double level;\n    int discard_anomalies;\n    int low;\n    double __up_down;\n    double anomaly_threshold;\n    double excess_threshold;\n    unsigned long Nt;\n    unsigned long n;\n    struct Tail tail;\n};\n</code></pre> <p>Main structure to run the SPOT algorithm.</p> Member Description <code>q</code> Probability of an anomaly. <code>level</code> Location of the tail (high quantile) <code>discard_anomalies</code> Flag anomalies (1 = flag, 0 = don't flag) <code>low</code> Upper/Lower tail choice (1 = lower tail, 0 = upper tail) <code>__up_down</code> Internal constant (+/- 1.0) <code>anomaly_threshold</code> Normal/abnormal threshold. <code>excess_threshold</code> Tail threshold. <code>Nt</code> Total number of excesses. <code>n</code> Total number of seen data. <code>tail</code> GPD Tail."},{"location":"70_API/#functions","title":"Functions","text":"spot_init <pre><code>int spot_init(struct [Spot](#structSpot) * spot, double q, int low, int discard_anomalies, double level, unsigned long max_excess)\n</code></pre> <p>Initialize the Spot structure.</p> Parameter Description <code>spot</code> Spot instance <code>q</code> Decision probability (Spot will flag extreme events that will have a probability lower than q) <code>low</code> Lower tail mode (0 by defaut for upper tail and 1 for lower tail) <code>discard_anomalies</code> Do not include anomalies in the model (default: 1, 0 otherwise) <code>level</code> Excess level (it is a high quantile that delimits the tail) <code>max_excess</code> Maximum number of data that are kept to analyze the tail spot_free <pre><code>void spot_free(struct [Spot](#structSpot) * spot)\n</code></pre> <p>Free the tail data.</p> Parameter Description <code>spot</code> Spot instance spot_fit <pre><code>int spot_fit(struct [Spot](#structSpot) * spot, double const * data, unsigned long size)\n</code></pre> <p>Compute the first excess and anomaly thresholds based on training data.</p> Parameter Description <code>spot</code> Spot instance <code>data</code> Buffer of input data <code>size</code> Size of the buffer spot_step <pre><code>int spot_step(struct [Spot](#structSpot) * spot, double x)\n</code></pre> <p>fit-predict step</p> Parameter Description <code>spot</code> Spot instance <code>x</code> new value spot_quantile <pre><code>double spot_quantile(struct [Spot](#structSpot) const * spot, double q)\n</code></pre> <p>Compute the value zq such that P(X&gt;zq) = q.</p> Parameter Description <code>spot</code> Spot instance <code>q</code> Low probability (it must be within the tail) spot_probability <pre><code>double spot_probability(struct [Spot](#structSpot) const * spot, double z)\n</code></pre> <p>Compute the probability p such that P(X&gt;z) = p.</p> Parameter Description <code>spot</code> Spot instance <code>z</code> High quantile (it must be within the tail) set_allocators <pre><code>void set_allocators(malloc_fn m, free_fn f)\n</code></pre> <p>Set the allocators object (malloc and free)</p> Parameter Description <code>m</code> pointer to a \"malloc\" function <code>f</code> pointer to a \"free\" function set_float_utils <pre><code>void set_float_utils(ldexp_fn l, frexp_fn f)\n</code></pre> <p>Set the ldexp/frexp functions.</p> <p>By default these functions are provided but the API allows to change them.</p> Parameter Description <code>l</code> pointer to a \"ldexp\" function <code>f</code> pointer to a \"frexp\" function libspot_version <pre><code>void libspot_version(char * buffer, unsigned long size)\n</code></pre> <p>Return the version of libspot.</p> Parameter Description <code>buffer</code> input buffer to fill with <code>size</code> size of the input buffer libspot_license <pre><code>void libspot_license(char * buffer, unsigned long size)\n</code></pre> <p>Return the license of the library.</p> Parameter Description <code>buffer</code> input buffer to fill with <code>size</code> size of the input buffer libspot_error <pre><code>void libspot_error(enum LibspotError err, char * buffer, unsigned long size)\n</code></pre> <p>Return a string related to an error code.</p> Parameter Description <code>err</code> error code <code>buffer</code> input buffer to fill with <code>size</code> size of the input buffer"},{"location":"internals/40_spot/","title":"SPOT algorithm","text":"<p>SPOT stands for Streaming Peaks Over Threshold. It is an adaptation of the POT method (you got it) for streaming data. In a word, this method computes high quantiles that are used as anomaly threshold.</p> <p></p>"},{"location":"internals/50_math/","title":"Math functions","text":"<p>libspot does not depend on the standard library, so its math. In particular, the SPOT algorithm needs both the exponential and the natural logarithm.</p>"},{"location":"internals/50_math/#natural-logarithm","title":"Natural logarithm","text":"<p>Several strategies exist to compute <code>log</code>. Currently we prefer accuracy against speed so we have compared different methods and parameters so as to be as close as possible as the standard library output (on my laptop  but you can also check it with online compiler). </p> <p>Our simple implementation is actually faster than the standard library while being as accurate as it.</p>"},{"location":"internals/50_math/#continued-fraction","title":"Continued fraction","text":"<p>We currently use the following continued fraction<sup>1</sup><sup>2</sup>:</p> <p>$$ \\log\\left(1 + z\\right) = \\dfrac{2 z}{2 + z + \\displaystyle\\KK_{m = 1}^{\\infty}\\left(\\frac{-m^2 z^2}{(2 m + 1) (2 + z)}\\right)} $$</p> <p>where</p> <p>$$ \\KK_{m = 1}^{\\infty}\\left(\\frac{-m^2 z^2}{(2 m + 1) (2 + z)}\\right) = -\\cfrac{z^2}{3 (2 + z) - \\cfrac{4 z^2}{5 (2 + z) - \\cfrac{9 z^2}{7 (2 + z) - \\cfrac{16 z^2}{9 (2 + z) - ...}}}} $$</p> <p>In practice, we truncate this expansion to depth $d$. For instance, the following pyton script leverages <code>sympy</code> and the recursive behavior of the continued fraction to output a truncated version of the expansion.</p> <pre><code>import sympy as sp\n\ndef K(x, d: int, m: int = 1):\n    if m == d:\n        return 0\n\n    a = -m * m\n    b = 2 * m + 1\n    return a * x * x / (b * (2 + x) + K(x, d, m + 1))\n\ndef log_cf(x, d: int):\n    z = x - 1\n    return 2 * z / (2 + z + K(z, d))\n\nx = sp.Symbol(\"x\")\nprint(log_cf(x, d=11))\n</code></pre>"},{"location":"internals/50_math/#truncation","title":"Truncation","text":"<p>The following code is used so as to find the \"best\" depth. We basically retrieve the max mantissa error and the relative error. Indeed we leverage the IEEE754 representation so as to turn the computation $\\log(x),  x\\in\\RR$ into $\\log(x),  x\\in[1, 2]$.</p> benchmark/log_cf_accuracy.c <p> </p> <p>The results on my laptop are presented below. Depths 9, 10 or 11 may be good candidates depending on the accuracy need.</p> depth max mantissa error max relative error 5 204513805 3.275499E-08 6 6065190 9.713924E-10 7 179516 2.875076E-11 8 5307 8.500201E-13 9 157 2.514663E-14 10 6 8.008480E-16 11 2 4.022239E-16 12 2 4.022239E-16 13 2 4.022239E-16 14 2 4.022239E-16"},{"location":"internals/50_math/#speed","title":"Speed","text":"<p>Let us present the speed of our implementation. In the following benchmark, we use an \"inline\" representation of the continued fraction with <code>depth = 11</code> (instead of the recursive definitions given above).</p> <p>We compare computation time of libspot vs the standard library (on 10M runs, $\\scriptsize 10^{-8}&lt;x&lt;10^{8}$).</p> benchmark/log_cf_speed.c <p> </p> <p>When we turn on optimization flags (like <code>-O2</code>) we see that the libspot implementation is faster.</p>"},{"location":"internals/50_math/#exponential","title":"Exponential","text":"<p>Once again we use a continued fraction to compute exponential. </p>"},{"location":"internals/50_math/#continued-fraction_1","title":"Continued fraction","text":"<p>We currently use the following continued fraction<sup>3</sup>:</p> <p>$$ \\exp\\left(z\\right) = 1 + \\cfrac{2 z}{2 - z + 2 \\displaystyle\\KK_{m = 1}^{\\infty}\\left(\\cfrac{a_m z^2}{1}\\right)} $$</p> <p>with  $$ a_m = \\dfrac{1}{4 (2 m - 1) (2 m + 1)} $$ so if we expand the continued fraction $$ \\KK_{m = 1}^{\\infty}\\left(\\cfrac{a_m z^2}{1}\\right) = \\cfrac{z^2 / 12}{1 + \\cfrac{z^2 / 60}{1 + \\cfrac{z^2 / 140}{1 + \\cfrac{z^2 / 252}{1 + \\cfrac{z^2 / 396}{1 + ...}}}}} $$</p> <pre><code>import sympy as sp\n\ndef K(z2, d: int, m: int = 1):\n    if m == d:\n        return 0\n\n    mm = 2 * m\n    a = 4 * (mm - 1) * (mm + 1)\n    return z2 / (a * (1 + K(z2, d, m + 1)))\n\ndef exp_cf(z, d: int):\n    z2 = z * z\n    return 1 + 2 * z / (2 - z + 2 * K(z2, d, 1))\n\nz = sp.Symbol(\"z\")\nprint(exp_cf(z, d=6))\n</code></pre>"},{"location":"internals/50_math/#truncation_1","title":"Truncation","text":"<p>The following benchmark leads us to choose <code>d = 6</code>.</p> benchmark/exp_cf_accuracy.c <p> </p> depth max mantissa error max relative error 3 6998321454 7.769708E-07 4 13281258 1.014192E-14 5 16126 1.790451E-12 6 81 1.017038E-14 7 90 1.017038E-14 8 90 1.017038E-14 9 90 1.017038E-14"},{"location":"internals/50_math/#speed_1","title":"Speed","text":"<p>Like in the previous <code>log</code> benchmark, we use an \"inline\" representation of the continued fraction with <code>depth = 6</code>. We compare computation time of libspot vs the standard library (on 10M runs, $\\scriptsize 10^{-8}&lt;x&lt;10^{2}$).</p> benchmark/exp_cf_speed.c <p> </p> <p>Once again, libspot implementation is faster when optimization flags are set.</p>"},{"location":"internals/50_math/#power","title":"Power","text":"<p>Finally, we need to compute $x^\\alpha$ when $x \\ge 0$ and $\\alpha \\in\\RR$. Currently we basically use our implementation of <code>exp</code> and <code>log</code> as $x^\\alpha = \\exp\\left(\\alpha \\log x\\right)$.</p> benchmark/pow_accuracy_speed.c <p> </p> <p>This current choice leads to worse performances than the standard library. This function is then likely to be improved in the future.</p> <ol> <li> <p>Formula (4.5) p.111</p> <p>Khovanskii, A. N. (1963). The application of continued fractions and their generalizations to problems in approximation theory (p. 144). Groningen: Noordhoff.</p> <p>\u21a9</p> </li> <li> <p>Formula (11.2.3) p.196</p> <p>Cuyt, A. A., Petersen, V., Verdonk, B., Waadeland, H., &amp; Jones, W. B. (2008). Handbook of continued fractions for special functions. Springer Science &amp; Business Media.</p> <p>\u21a9</p> </li> <li> <p>Formula (11.1.2) p.194</p> <p>Cuyt, A. A., Petersen, V., Verdonk, B., Waadeland, H., &amp; Jones, W. B. (2008). Handbook of continued fractions for special functions. Springer Science &amp; Business Media.</p> <p>\u21a9</p> </li> </ol>"},{"location":"internals/60_fit/","title":"Initial fit","text":"<p>The fit steps is required to calibrate the algorithm and compute a first decision threshold.</p> <p>To compute this extreme threshold, we first need a high threshold, that is basically a high quantile (defined by the <code>level</code> parameter). This quantile is used to delimitate the tail of the distribution.</p> <p>A simple way to estimate this quantile is to compute it emirically from the initial batch. For that we need to sort the data... This method gives the right empirical quantile but it requires to implement a sort algorithm (remember <code>-nostdlib</code> ).</p> <p>Actually, we do not need the highest precision quantile given <code>level</code>. We roughly want a high value. So, libspot uses an approximate quantile algorithm, a.k.a. P<sup>2</sup> (see https://aakinshin.net/posts/p2-quantile-estimator/ for a very good description).</p> <p>The benchmark below shows that it is faster and also that it is quite accurate even with a small initial batch.</p> benchmark/p2.c <p> </p>"}]}